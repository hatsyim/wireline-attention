{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taufikmh/miniconda3/envs/mlcoursegpu/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lasio\n",
    "import xgboost as xgb\n",
    "import scooby\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from scipy.signal import filtfilt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score, mean_squared_error \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from dataset import *\n",
    "# from model import *\n",
    "# from train import *\n",
    "# from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_csv('../../../labs/data/train.csv', sep=';')\n",
    "train_data['WELL'] = train_data['WELL'].astype('category').cat.codes\n",
    "\n",
    "# Load the testing data\n",
    "test_data = pd.read_csv('../../../labs/data/leaderboard_test_features.csv', sep=';')\n",
    "test_data['WELL'] = test_data['WELL'].astype('category').cat.codes\n",
    "\n",
    "train_data = train_data[['WELL', 'DEPTH_MD', 'CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'NPHI', 'PEF', 'DTS', 'DTC']].copy().dropna()\n",
    "test_data = test_data[~np.isnan(test_data.DTS.values)][['WELL', 'DEPTH_MD','CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'NPHI', 'PEF', 'DTS', 'DTC']].copy().dropna()\n",
    "\n",
    "train_data = train_data.mask(train_data>train_data.quantile(0.995), train_data.quantile(0.995), axis=1)\n",
    "test_data = test_data.mask(test_data>test_data.quantile(0.995), test_data.quantile(0.995), axis=1)\n",
    "\n",
    "# Select input\n",
    "X_train = train_data[['CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'NPHI', 'PEF', 'DTC','WELL']].copy()\n",
    "y_train = train_data[['DTS', 'WELL']].copy()\n",
    "\n",
    "X_test = test_data[['CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'NPHI', 'PEF', 'DTC','WELL']].copy()\n",
    "y_test = test_data[['DTS', 'WELL']].copy()\n",
    "\n",
    "# Tranform RES logs\n",
    "X_train['RSHA']=np.log(X_train.RSHA.values)\n",
    "X_test['RSHA']=np.log(X_test.RSHA.values)\n",
    "X_train['RMED']=np.log(X_train.RMED.values)\n",
    "X_test['RMED']=np.log(X_test.RMED.values)\n",
    "X_train['RDEP']=np.log(X_train.RDEP.values)\n",
    "X_test['RDEP']=np.log(X_test.RDEP.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Train Set\n",
    "X_train = torch.from_numpy(X_train.to_numpy()).float().view(-1,X_train.shape[1])\n",
    "y_train = torch.from_numpy(y_train.to_numpy()).float().view(-1,y_train.shape[1])\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "\n",
    "# Define Test Set\n",
    "X_test = torch.from_numpy(X_test.to_numpy()).float().view(-1,X_test.shape[1])\n",
    "y_test = torch.from_numpy(y_test.to_numpy()).float().view(-1,y_test.shape[1])\n",
    "valid_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Use Pytorch's functionality to load data in batches. Here we use full-batch training again.\n",
    "train_loader = DataLoader(train_dataset, batch_size=X_train.size(0), shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=X_test.size(0), shuffle=False)\n",
    "\n",
    "torch.save(train_loader, '../data/train_loader.pth')    \n",
    "torch.save(valid_loader, '../data/valid_loader.pth')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b18b43862d5e8a1f681a122a0aa109ab505f982ae47976d238af420d4dca458e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('mlcoursegpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
